# æ•¸æ“šåˆ†æèˆ‡å ±è¡¨è¦åŠƒ

## 1. åŠŸèƒ½æ¦‚è¿°

### 1.1 æœå‹™ç¯„åœ

**æ ¸å¿ƒåˆ†æåŠŸèƒ½**
- ç”¨æˆ¶è¡Œç‚ºåˆ†æ
- å…§å®¹è¡¨ç¾åˆ†æ
- ç¤¾ç¾¤äº’å‹•åˆ†æ
- æ¥­å‹™æŒ‡æ¨™ç›£æ§
- å¯¦æ™‚æ•¸æ“šå„€è¡¨æ¿
- è‡ªå®šç¾©å ±è¡¨ç”Ÿæˆ

**ç›®æ¨™ç”¨æˆ¶**
- å¹³å°ç®¡ç†å“¡
- ç”¢å“ç¶“ç†
- é‹ç‡Ÿåœ˜éšŠ
- æ•¸æ“šåˆ†æå¸«
- ç¤¾ç¾¤ç®¡ç†å“¡

**æœå‹™ç›®æ¨™**
- æ•¸æ“šé©…å‹•æ±ºç­–
- ç”¨æˆ¶é«”é©—å„ªåŒ–
- æ¥­å‹™å¢é•·æ´å¯Ÿ
- é¢¨éšªé è­¦ç›£æ§
- é‹ç‡Ÿæ•ˆç‡æå‡

### 1.2 åˆ†æé¡å‹

**æè¿°æ€§åˆ†æ**
- æ­·å²æ•¸æ“šçµ±è¨ˆ
- è¶¨å‹¢è®ŠåŒ–åˆ†æ
- ç”¨æˆ¶ç•«åƒæè¿°
- å…§å®¹åˆ†ä½ˆçµ±è¨ˆ

**è¨ºæ–·æ€§åˆ†æ**
- ç•°å¸¸åŸå› åˆ†æ
- ç›¸é—œæ€§åˆ†æ
- æ¼æ–—åˆ†æ
- ç•™å­˜åˆ†æ

**é æ¸¬æ€§åˆ†æ**
- ç”¨æˆ¶æµå¤±é æ¸¬
- å…§å®¹ç†±åº¦é æ¸¬
- å¢é•·è¶¨å‹¢é æ¸¬
- é¢¨éšªé è­¦

**è¦ç¯„æ€§åˆ†æ**
- æ¨è–¦ç­–ç•¥
- å„ªåŒ–å»ºè­°
- A/Bæ¸¬è©¦åˆ†æ
- æ±ºç­–æ”¯æ´

## 2. æŠ€è¡“æ–¹æ¡ˆæ¯”è¼ƒ

### 2.1 æ•¸æ“šåˆ†ææŠ€è¡“æ¯”è¼ƒ

| æŠ€è¡“æ–¹æ¡ˆ | å„ªé» | ç¼ºé» | é©ç”¨å ´æ™¯ | æˆæœ¬ | æ¨è–¦åº¦ |
|---------|------|------|----------|------|--------|
| Python + Pandas | éˆæ´»å¼·å¤§ï¼Œç”Ÿæ…‹è±å¯Œ | æ€§èƒ½é™åˆ¶ï¼Œå…§å­˜æ¶ˆè€— | ä¸­å°è¦æ¨¡åˆ†æ | ä½ | â­â­â­â­â­ |
| Apache Spark | å¤§æ•¸æ“šè™•ç†ï¼Œåˆ†æ•£å¼ | è¤‡é›œåº¦é«˜ï¼Œè³‡æºéœ€æ±‚å¤§ | å¤§è¦æ¨¡æ•¸æ“š | é«˜ | â­â­â­ |
| ClickHouse | é«˜æ€§èƒ½OLAPï¼Œå¯¦æ™‚æŸ¥è©¢ | å­¸ç¿’æˆæœ¬ï¼Œç¶­è­·è¤‡é›œ | å¯¦æ™‚åˆ†æ | ä¸­ | â­â­â­â­ |
| PostgreSQL + TimescaleDB | æ™‚åºæ•¸æ“šå„ªåŒ–ï¼ŒSQLå‹å¥½ | æ“´å±•æ€§é™åˆ¶ | æ™‚åºåˆ†æ | ä½ | â­â­â­â­ |
| Grafana + Prometheus | ç›£æ§å¯è¦–åŒ–ï¼Œé–‹æºå…è²» | åŠŸèƒ½ç›¸å°ç°¡å–® | ç³»çµ±ç›£æ§ | ä½ | â­â­â­â­â­ |

**æ¨è–¦æ–¹æ¡ˆ**ï¼šPython + Pandas + PostgreSQL + Grafanaï¼ˆæˆæœ¬æ•ˆç›Šæœ€ä½³ï¼‰

### 2.2 é–‹æºæ•¸æ“šåˆ†æå¹³å°

#### 2.2.1 æ•¸æ“šè™•ç†å¼•æ“

```python
# åŸºæ–¼ Python çš„æ•¸æ“šåˆ†æå¼•æ“
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import psycopg2
from sqlalchemy import create_engine
import redis
import json
from typing import Dict, List, Optional, Any
import logging
from concurrent.futures import ThreadPoolExecutor
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots

class DataAnalyticsEngine:
    def __init__(self, db_config, redis_config=None):
        self.db_engine = create_engine(
            f"postgresql://{db_config['user']}:{db_config['password']}@"
            f"{db_config['host']}:{db_config['port']}/{db_config['database']}"
        )
        
        self.redis_client = None
        if redis_config:
            self.redis_client = redis.Redis(
                host=redis_config['host'],
                port=redis_config['port'],
                db=redis_config['db']
            )
        
        self.setup_logging()
        self.cache_ttl = 3600  # 1å°æ™‚å¿«å–
    
    def setup_logging(self):
        """è¨­ç½®æ—¥èªŒè¨˜éŒ„"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        self.logger = logging.getLogger(__name__)
    
    def get_cached_data(self, cache_key):
        """ç²å–å¿«å–æ•¸æ“š"""
        if not self.redis_client:
            return None
        
        try:
            cached_data = self.redis_client.get(cache_key)
            if cached_data:
                return json.loads(cached_data)
        except Exception as e:
            self.logger.warning(f"å¿«å–è®€å–å¤±æ•—: {e}")
        
        return None
    
    def set_cached_data(self, cache_key, data, ttl=None):
        """è¨­ç½®å¿«å–æ•¸æ“š"""
        if not self.redis_client:
            return
        
        try:
            ttl = ttl or self.cache_ttl
            self.redis_client.setex(
                cache_key, 
                ttl, 
                json.dumps(data, default=str)
            )
        except Exception as e:
            self.logger.warning(f"å¿«å–å¯«å…¥å¤±æ•—: {e}")
    
    def execute_query(self, query, params=None, use_cache=True):
        """åŸ·è¡ŒSQLæŸ¥è©¢"""
        cache_key = f"query:{hash(query + str(params or ''))}"
        
        # å˜—è©¦å¾å¿«å–ç²å–
        if use_cache:
            cached_result = self.get_cached_data(cache_key)
            if cached_result is not None:
                return pd.DataFrame(cached_result)
        
        try:
            # åŸ·è¡ŒæŸ¥è©¢
            df = pd.read_sql_query(query, self.db_engine, params=params)
            
            # å¿«å–çµæœ
            if use_cache and len(df) > 0:
                self.set_cached_data(cache_key, df.to_dict('records'))
            
            return df
            
        except Exception as e:
            self.logger.error(f"æŸ¥è©¢åŸ·è¡Œå¤±æ•—: {e}")
            return pd.DataFrame()
    
    def get_user_analytics(self, start_date=None, end_date=None):
        """ç”¨æˆ¶åˆ†ææ•¸æ“š"""
        if not start_date:
            start_date = datetime.now() - timedelta(days=30)
        if not end_date:
            end_date = datetime.now()
        
        # ç”¨æˆ¶è¨»å†Šè¶¨å‹¢
        registration_query = """
        SELECT 
            DATE(created_at) as date,
            COUNT(*) as new_users,
            COUNT(*) OVER (ORDER BY DATE(created_at)) as cumulative_users
        FROM users 
        WHERE created_at BETWEEN %(start_date)s AND %(end_date)s
        GROUP BY DATE(created_at)
        ORDER BY date
        """
        
        registration_data = self.execute_query(
            registration_query, 
            {'start_date': start_date, 'end_date': end_date}
        )
        
        # ç”¨æˆ¶æ´»èºåº¦
        activity_query = """
        SELECT 
            DATE(created_at) as date,
            COUNT(DISTINCT user_id) as daily_active_users
        FROM user_behavior_logs 
        WHERE created_at BETWEEN %(start_date)s AND %(end_date)s
        GROUP BY DATE(created_at)
        ORDER BY date
        """
        
        activity_data = self.execute_query(
            activity_query,
            {'start_date': start_date, 'end_date': end_date}
        )
        
        # ç”¨æˆ¶ç•™å­˜åˆ†æ
        retention_data = self.calculate_user_retention(start_date, end_date)
        
        # ç”¨æˆ¶è¡Œç‚ºåˆ†ä½ˆ
        behavior_query = """
        SELECT 
            action_type,
            COUNT(*) as action_count,
            COUNT(DISTINCT user_id) as unique_users
        FROM user_behavior_logs 
        WHERE created_at BETWEEN %(start_date)s AND %(end_date)s
        GROUP BY action_type
        ORDER BY action_count DESC
        """
        
        behavior_data = self.execute_query(
            behavior_query,
            {'start_date': start_date, 'end_date': end_date}
        )
        
        return {
            'registration_trend': registration_data.to_dict('records'),
            'activity_trend': activity_data.to_dict('records'),
            'retention_analysis': retention_data,
            'behavior_distribution': behavior_data.to_dict('records')
        }
    
    def calculate_user_retention(self, start_date, end_date):
        """è¨ˆç®—ç”¨æˆ¶ç•™å­˜ç‡"""
        retention_query = """
        WITH user_first_activity AS (
            SELECT 
                user_id,
                MIN(DATE(created_at)) as first_activity_date
            FROM user_behavior_logs
            WHERE created_at BETWEEN %(start_date)s AND %(end_date)s
            GROUP BY user_id
        ),
        retention_cohorts AS (
            SELECT 
                ufa.first_activity_date as cohort_date,
                COUNT(DISTINCT ufa.user_id) as cohort_size,
                COUNT(DISTINCT CASE 
                    WHEN DATE(ubl.created_at) = ufa.first_activity_date + INTERVAL '1 day' 
                    THEN ufa.user_id END) as day_1_retention,
                COUNT(DISTINCT CASE 
                    WHEN DATE(ubl.created_at) = ufa.first_activity_date + INTERVAL '7 days' 
                    THEN ufa.user_id END) as day_7_retention,
                COUNT(DISTINCT CASE 
                    WHEN DATE(ubl.created_at) = ufa.first_activity_date + INTERVAL '30 days' 
                    THEN ufa.user_id END) as day_30_retention
            FROM user_first_activity ufa
            LEFT JOIN user_behavior_logs ubl ON ufa.user_id = ubl.user_id
            GROUP BY ufa.first_activity_date
            ORDER BY ufa.first_activity_date
        )
        SELECT 
            cohort_date,
            cohort_size,
            ROUND(day_1_retention::numeric / cohort_size * 100, 2) as day_1_retention_rate,
            ROUND(day_7_retention::numeric / cohort_size * 100, 2) as day_7_retention_rate,
            ROUND(day_30_retention::numeric / cohort_size * 100, 2) as day_30_retention_rate
        FROM retention_cohorts
        WHERE cohort_size >= 10
        """
        
        return self.execute_query(
            retention_query,
            {'start_date': start_date, 'end_date': end_date}
        ).to_dict('records')
    
    def get_content_analytics(self, start_date=None, end_date=None):
        """å…§å®¹åˆ†ææ•¸æ“š"""
        if not start_date:
            start_date = datetime.now() - timedelta(days=30)
        if not end_date:
            end_date = datetime.now()
        
        # å…§å®¹ç™¼å¸ƒè¶¨å‹¢
        content_trend_query = """
        SELECT 
            DATE(created_at) as date,
            COUNT(*) as posts_count,
            COUNT(DISTINCT user_id) as active_creators
        FROM posts 
        WHERE created_at BETWEEN %(start_date)s AND %(end_date)s
        GROUP BY DATE(created_at)
        ORDER BY date
        """
        
        content_trend = self.execute_query(
            content_trend_query,
            {'start_date': start_date, 'end_date': end_date}
        )
        
        # ç†±é–€å…§å®¹åˆ†æ
        popular_content_query = """
        SELECT 
            p.id,
            p.title,
            p.user_id,
            u.username,
            p.created_at,
            COUNT(DISTINCT l.user_id) as likes_count,
            COUNT(DISTINCT c.id) as comments_count,
            COUNT(DISTINCT s.user_id) as shares_count
        FROM posts p
        LEFT JOIN users u ON p.user_id = u.id
        LEFT JOIN likes l ON p.id = l.post_id
        LEFT JOIN comments c ON p.id = c.post_id
        LEFT JOIN shares s ON p.id = s.post_id
        WHERE p.created_at BETWEEN %(start_date)s AND %(end_date)s
        GROUP BY p.id, p.title, p.user_id, u.username, p.created_at
        ORDER BY (likes_count + comments_count * 2 + shares_count * 3) DESC
        LIMIT 20
        """
        
        popular_content = self.execute_query(
            popular_content_query,
            {'start_date': start_date, 'end_date': end_date}
        )
        
        # å…§å®¹é¡å‹åˆ†ä½ˆ
        content_type_query = """
        SELECT 
            content_type,
            COUNT(*) as count,
            AVG(COALESCE(likes_count, 0)) as avg_likes,
            AVG(COALESCE(comments_count, 0)) as avg_comments
        FROM posts 
        WHERE created_at BETWEEN %(start_date)s AND %(end_date)s
        GROUP BY content_type
        ORDER BY count DESC
        """
        
        content_type_dist = self.execute_query(
            content_type_query,
            {'start_date': start_date, 'end_date': end_date}
        )
        
        # å…§å®¹äº’å‹•åˆ†æ
        engagement_query = """
        SELECT 
            DATE(p.created_at) as date,
            COUNT(DISTINCT l.user_id) as total_likes,
            COUNT(DISTINCT c.id) as total_comments,
            COUNT(DISTINCT s.user_id) as total_shares,
            COUNT(DISTINCT p.id) as total_posts,
            ROUND(COUNT(DISTINCT l.user_id)::numeric / COUNT(DISTINCT p.id), 2) as avg_likes_per_post
        FROM posts p
        LEFT JOIN likes l ON p.id = l.post_id AND DATE(l.created_at) = DATE(p.created_at)
        LEFT JOIN comments c ON p.id = c.post_id AND DATE(c.created_at) = DATE(p.created_at)
        LEFT JOIN shares s ON p.id = s.post_id AND DATE(s.created_at) = DATE(p.created_at)
        WHERE p.created_at BETWEEN %(start_date)s AND %(end_date)s
        GROUP BY DATE(p.created_at)
        ORDER BY date
        """
        
        engagement_data = self.execute_query(
            engagement_query,
            {'start_date': start_date, 'end_date': end_date}
        )
        
        return {
            'content_trend': content_trend.to_dict('records'),
            'popular_content': popular_content.to_dict('records'),
            'content_type_distribution': content_type_dist.to_dict('records'),
            'engagement_analysis': engagement_data.to_dict('records')
        }
    
    def get_social_analytics(self, start_date=None, end_date=None):
        """ç¤¾äº¤äº’å‹•åˆ†æ"""
        if not start_date:
            start_date = datetime.now() - timedelta(days=30)
        if not end_date:
            end_date = datetime.now()
        
        # é—œæ³¨é—œä¿‚åˆ†æ
        follow_query = """
        SELECT 
            DATE(created_at) as date,
            COUNT(*) as new_follows,
            COUNT(*) OVER (ORDER BY DATE(created_at)) as cumulative_follows
        FROM follows 
        WHERE created_at BETWEEN %(start_date)s AND %(end_date)s
        GROUP BY DATE(created_at)
        ORDER BY date
        """
        
        follow_data = self.execute_query(
            follow_query,
            {'start_date': start_date, 'end_date': end_date}
        )
        
        # äº’å‹•ç†±åº¦åˆ†æ
        interaction_query = """
        SELECT 
            DATE(created_at) as date,
            'likes' as interaction_type,
            COUNT(*) as count
        FROM likes 
        WHERE created_at BETWEEN %(start_date)s AND %(end_date)s
        GROUP BY DATE(created_at)
        
        UNION ALL
        
        SELECT 
            DATE(created_at) as date,
            'comments' as interaction_type,
            COUNT(*) as count
        FROM comments 
        WHERE created_at BETWEEN %(start_date)s AND %(end_date)s
        GROUP BY DATE(created_at)
        
        UNION ALL
        
        SELECT 
            DATE(created_at) as date,
            'shares' as interaction_type,
            COUNT(*) as count
        FROM shares 
        WHERE created_at BETWEEN %(start_date)s AND %(end_date)s
        GROUP BY DATE(created_at)
        
        ORDER BY date, interaction_type
        """
        
        interaction_data = self.execute_query(
            interaction_query,
            {'start_date': start_date, 'end_date': end_date}
        )
        
        # ç¤¾ç¾¤ç¶²çµ¡åˆ†æ
        network_query = """
        WITH user_connections AS (
            SELECT 
                follower_id as user_id,
                COUNT(*) as following_count
            FROM follows
            GROUP BY follower_id
        ),
        user_followers AS (
            SELECT 
                following_id as user_id,
                COUNT(*) as followers_count
            FROM follows
            GROUP BY following_id
        )
        SELECT 
            u.id,
            u.username,
            COALESCE(uc.following_count, 0) as following_count,
            COALESCE(uf.followers_count, 0) as followers_count,
            CASE 
                WHEN COALESCE(uf.followers_count, 0) > 1000 THEN 'influencer'
                WHEN COALESCE(uf.followers_count, 0) > 100 THEN 'active'
                ELSE 'regular'
            END as user_type
        FROM users u
        LEFT JOIN user_connections uc ON u.id = uc.user_id
        LEFT JOIN user_followers uf ON u.id = uf.user_id
        WHERE u.created_at <= %(end_date)s
        ORDER BY followers_count DESC
        LIMIT 100
        """
        
        network_data = self.execute_query(
            network_query,
            {'end_date': end_date}
        )
        
        return {
            'follow_trend': follow_data.to_dict('records'),
            'interaction_trend': interaction_data.to_dict('records'),
            'network_analysis': network_data.to_dict('records')
        }
    
    def get_business_metrics(self, start_date=None, end_date=None):
        """æ¥­å‹™æŒ‡æ¨™åˆ†æ"""
        if not start_date:
            start_date = datetime.now() - timedelta(days=30)
        if not end_date:
            end_date = datetime.now()
        
        # é—œéµæ¥­å‹™æŒ‡æ¨™
        kpi_query = """
        WITH daily_metrics AS (
            SELECT 
                DATE(created_at) as date,
                COUNT(DISTINCT user_id) as daily_active_users
            FROM user_behavior_logs
            WHERE created_at BETWEEN %(start_date)s AND %(end_date)s
            GROUP BY DATE(created_at)
        ),
        weekly_metrics AS (
            SELECT 
                DATE_TRUNC('week', created_at) as week,
                COUNT(DISTINCT user_id) as weekly_active_users
            FROM user_behavior_logs
            WHERE created_at BETWEEN %(start_date)s AND %(end_date)s
            GROUP BY DATE_TRUNC('week', created_at)
        ),
        monthly_metrics AS (
            SELECT 
                DATE_TRUNC('month', created_at) as month,
                COUNT(DISTINCT user_id) as monthly_active_users
            FROM user_behavior_logs
            WHERE created_at BETWEEN %(start_date)s AND %(end_date)s
            GROUP BY DATE_TRUNC('month', created_at)
        )
        SELECT 
            'DAU' as metric_name,
            AVG(daily_active_users) as avg_value,
            MAX(daily_active_users) as max_value,
            MIN(daily_active_users) as min_value
        FROM daily_metrics
        
        UNION ALL
        
        SELECT 
            'WAU' as metric_name,
            AVG(weekly_active_users) as avg_value,
            MAX(weekly_active_users) as max_value,
            MIN(weekly_active_users) as min_value
        FROM weekly_metrics
        
        UNION ALL
        
        SELECT 
            'MAU' as metric_name,
            AVG(monthly_active_users) as avg_value,
            MAX(monthly_active_users) as max_value,
            MIN(monthly_active_users) as min_value
        FROM monthly_metrics
        """
        
        kpi_data = self.execute_query(
            kpi_query,
            {'start_date': start_date, 'end_date': end_date}
        )
        
        # å¢é•·æŒ‡æ¨™
        growth_query = """
        WITH monthly_stats AS (
            SELECT 
                DATE_TRUNC('month', created_at) as month,
                COUNT(*) as new_users
            FROM users
            WHERE created_at BETWEEN %(start_date)s AND %(end_date)s
            GROUP BY DATE_TRUNC('month', created_at)
            ORDER BY month
        )
        SELECT 
            month,
            new_users,
            LAG(new_users) OVER (ORDER BY month) as prev_month_users,
            CASE 
                WHEN LAG(new_users) OVER (ORDER BY month) > 0 THEN
                    ROUND((new_users - LAG(new_users) OVER (ORDER BY month))::numeric / 
                          LAG(new_users) OVER (ORDER BY month) * 100, 2)
                ELSE 0
            END as growth_rate
        FROM monthly_stats
        """
        
        growth_data = self.execute_query(
            growth_query,
            {'start_date': start_date, 'end_date': end_date}
        )
        
        return {
            'key_metrics': kpi_data.to_dict('records'),
            'growth_metrics': growth_data.to_dict('records')
        }
    
    def generate_dashboard_data(self, date_range='30d'):
        """ç”Ÿæˆå„€è¡¨æ¿æ•¸æ“š"""
        # è§£ææ—¥æœŸç¯„åœ
        if date_range == '7d':
            start_date = datetime.now() - timedelta(days=7)
        elif date_range == '30d':
            start_date = datetime.now() - timedelta(days=30)
        elif date_range == '90d':
            start_date = datetime.now() - timedelta(days=90)
        else:
            start_date = datetime.now() - timedelta(days=30)
        
        end_date = datetime.now()
        
        # ä¸¦è¡Œç²å–å„é¡åˆ†ææ•¸æ“š
        with ThreadPoolExecutor(max_workers=4) as executor:
            user_future = executor.submit(self.get_user_analytics, start_date, end_date)
            content_future = executor.submit(self.get_content_analytics, start_date, end_date)
            social_future = executor.submit(self.get_social_analytics, start_date, end_date)
            business_future = executor.submit(self.get_business_metrics, start_date, end_date)
            
            # ç²å–çµæœ
            user_analytics = user_future.result()
            content_analytics = content_future.result()
            social_analytics = social_future.result()
            business_metrics = business_future.result()
        
        return {
            'user_analytics': user_analytics,
            'content_analytics': content_analytics,
            'social_analytics': social_analytics,
            'business_metrics': business_metrics,
            'generated_at': datetime.now().isoformat(),
            'date_range': {
                'start': start_date.isoformat(),
                'end': end_date.isoformat()
            }
        }
    
    def create_visualization(self, data_type, data, chart_type='line'):
        """å‰µå»ºæ•¸æ“šå¯è¦–åŒ–"""
        if data_type == 'user_registration':
            df = pd.DataFrame(data)
            if chart_type == 'line':
                fig = px.line(df, x='date', y='new_users', 
                             title='ç”¨æˆ¶è¨»å†Šè¶¨å‹¢')
            else:
                fig = px.bar(df, x='date', y='new_users', 
                            title='ç”¨æˆ¶è¨»å†Šè¶¨å‹¢')
        
        elif data_type == 'content_engagement':
            df = pd.DataFrame(data)
            fig = make_subplots(
                rows=2, cols=2,
                subplot_titles=('è®šæ•¸è¶¨å‹¢', 'è©•è«–è¶¨å‹¢', 'åˆ†äº«è¶¨å‹¢', 'è²¼æ–‡æ•¸è¶¨å‹¢')
            )
            
            fig.add_trace(
                go.Scatter(x=df['date'], y=df['total_likes'], name='è®šæ•¸'),
                row=1, col=1
            )
            fig.add_trace(
                go.Scatter(x=df['date'], y=df['total_comments'], name='è©•è«–æ•¸'),
                row=1, col=2
            )
            fig.add_trace(
                go.Scatter(x=df['date'], y=df['total_shares'], name='åˆ†äº«æ•¸'),
                row=2, col=1
            )
            fig.add_trace(
                go.Scatter(x=df['date'], y=df['total_posts'], name='è²¼æ–‡æ•¸'),
                row=2, col=2
            )
        
        elif data_type == 'user_retention':
            df = pd.DataFrame(data)
            fig = go.Figure()
            
            fig.add_trace(go.Scatter(
                x=df['cohort_date'], 
                y=df['day_1_retention_rate'],
                name='1æ—¥ç•™å­˜ç‡',
                line=dict(color='blue')
            ))
            
            fig.add_trace(go.Scatter(
                x=df['cohort_date'], 
                y=df['day_7_retention_rate'],
                name='7æ—¥ç•™å­˜ç‡',
                line=dict(color='green')
            ))
            
            fig.add_trace(go.Scatter(
                x=df['cohort_date'], 
                y=df['day_30_retention_rate'],
                name='30æ—¥ç•™å­˜ç‡',
                line=dict(color='red')
            ))
            
            fig.update_layout(title='ç”¨æˆ¶ç•™å­˜ç‡åˆ†æ')
        
        else:
            # é»˜èªåœ–è¡¨
            fig = go.Figure()
            fig.add_annotation(text="æš«ç„¡æ•¸æ“š", x=0.5, y=0.5)
        
        return fig.to_json()
    
    def export_report(self, data, format='json', filename=None):
        """å°å‡ºå ±è¡¨"""
        if not filename:
            filename = f"analytics_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        if format == 'json':
            filepath = f"{filename}.json"
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2, default=str)
        
        elif format == 'csv':
            # å°‡åµŒå¥—æ•¸æ“šå±•å¹³ä¸¦å°å‡ºç‚ºCSV
            flattened_data = []
            for key, value in data.items():
                if isinstance(value, list):
                    for item in value:
                        flattened_item = {'category': key}
                        flattened_item.update(item)
                        flattened_data.append(flattened_item)
            
            df = pd.DataFrame(flattened_data)
            filepath = f"{filename}.csv"
            df.to_csv(filepath, index=False, encoding='utf-8')
        
        elif format == 'excel':
            filepath = f"{filename}.xlsx"
            with pd.ExcelWriter(filepath, engine='openpyxl') as writer:
                for key, value in data.items():
                    if isinstance(value, list) and value:
                        df = pd.DataFrame(value)
                        df.to_excel(writer, sheet_name=key[:31], index=False)
        
        self.logger.info(f"å ±è¡¨å·²å°å‡º: {filepath}")
        return filepath
```

#### 2.2.2 å¯¦æ™‚ç›£æ§ç³»çµ±

```python
# å¯¦æ™‚ç›£æ§èˆ‡å‘Šè­¦ç³»çµ±
import asyncio
import websockets
import json
from datetime import datetime, timedelta
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
import requests
from typing import Dict, List, Callable

class RealTimeMonitor:
    def __init__(self, analytics_engine, alert_config):
        self.analytics_engine = analytics_engine
        self.alert_config = alert_config
        self.alert_rules = []
        self.websocket_clients = set()
        self.monitoring_active = False
        self.setup_logging()
    
    def setup_logging(self):
        """è¨­ç½®æ—¥èªŒè¨˜éŒ„"""
        self.logger = logging.getLogger(__name__)
    
    def add_alert_rule(self, name, condition, threshold, action):
        """æ·»åŠ å‘Šè­¦è¦å‰‡"""
        rule = {
            'name': name,
            'condition': condition,  # å‡½æ•¸ï¼Œè¿”å›æ•¸å€¼
            'threshold': threshold,
            'action': action,  # å‘Šè­¦å‹•ä½œ
            'last_triggered': None,
            'cooldown': 300  # 5åˆ†é˜å†·å»æœŸ
        }
        self.alert_rules.append(rule)
    
    def setup_default_rules(self):
        """è¨­ç½®é»˜èªç›£æ§è¦å‰‡"""
        # ç”¨æˆ¶æ´»èºåº¦ç•°å¸¸
        self.add_alert_rule(
            name="ä½æ´»èºåº¦å‘Šè­¦",
            condition=lambda: self.get_current_active_users(),
            threshold=10,  # ç•¶å‰æ´»èºç”¨æˆ¶å°‘æ–¼10äºº
            action=self.send_low_activity_alert
        )
        
        # éŒ¯èª¤ç‡ç•°å¸¸
        self.add_alert_rule(
            name="é«˜éŒ¯èª¤ç‡å‘Šè­¦",
            condition=lambda: self.get_error_rate(),
            threshold=0.05,  # éŒ¯èª¤ç‡è¶…é5%
            action=self.send_error_rate_alert
        )
        
        # å…§å®¹ç™¼å¸ƒç•°å¸¸
        self.add_alert_rule(
            name="å…§å®¹ç™¼å¸ƒç•°å¸¸",
            condition=lambda: self.get_content_publish_rate(),
            threshold=1,  # æ¯å°æ™‚ç™¼å¸ƒå°‘æ–¼1ç¯‡
            action=self.send_content_alert
        )
    
    def get_current_active_users(self):
        """ç²å–ç•¶å‰æ´»èºç”¨æˆ¶æ•¸"""
        query = """
        SELECT COUNT(DISTINCT user_id) as active_users
        FROM user_behavior_logs
        WHERE created_at >= NOW() - INTERVAL '1 hour'
        """
        
        result = self.analytics_engine.execute_query(query, use_cache=False)
        return result.iloc[0]['active_users'] if len(result) > 0 else 0
    
    def get_error_rate(self):
        """ç²å–éŒ¯èª¤ç‡"""
        # é€™è£¡æ‡‰è©²å¾æ‡‰ç”¨æ—¥èªŒæˆ–ç›£æ§ç³»çµ±ç²å–éŒ¯èª¤ç‡
        # æš«æ™‚è¿”å›æ¨¡æ“¬æ•¸æ“š
        return 0.02
    
    def get_content_publish_rate(self):
        """ç²å–å…§å®¹ç™¼å¸ƒç‡"""
        query = """
        SELECT COUNT(*) as posts_count
        FROM posts
        WHERE created_at >= NOW() - INTERVAL '1 hour'
        """
        
        result = self.analytics_engine.execute_query(query, use_cache=False)
        return result.iloc[0]['posts_count'] if len(result) > 0 else 0
    
    def check_alert_rules(self):
        """æª¢æŸ¥å‘Šè­¦è¦å‰‡"""
        current_time = datetime.now()
        
        for rule in self.alert_rules:
            try:
                # æª¢æŸ¥å†·å»æœŸ
                if (rule['last_triggered'] and 
                    (current_time - rule['last_triggered']).seconds < rule['cooldown']):
                    continue
                
                # åŸ·è¡Œæ¢ä»¶æª¢æŸ¥
                current_value = rule['condition']()
                
                # åˆ¤æ–·æ˜¯å¦è§¸ç™¼å‘Šè­¦
                if current_value < rule['threshold']:
                    rule['last_triggered'] = current_time
                    rule['action'](rule['name'], current_value, rule['threshold'])
                    
                    self.logger.warning(
                        f"å‘Šè­¦è§¸ç™¼: {rule['name']}, ç•¶å‰å€¼: {current_value}, é–¾å€¼: {rule['threshold']}"
                    )
                    
            except Exception as e:
                self.logger.error(f"å‘Šè­¦è¦å‰‡æª¢æŸ¥å¤±æ•— {rule['name']}: {e}")
    
    def send_low_activity_alert(self, rule_name, current_value, threshold):
        """ç™¼é€ä½æ´»èºåº¦å‘Šè­¦"""
        message = f"å‘Šè­¦: {rule_name}\nç•¶å‰æ´»èºç”¨æˆ¶: {current_value}\né–¾å€¼: {threshold}"
        self.send_alert(message)
    
    def send_error_rate_alert(self, rule_name, current_value, threshold):
        """ç™¼é€éŒ¯èª¤ç‡å‘Šè­¦"""
        message = f"å‘Šè­¦: {rule_name}\nç•¶å‰éŒ¯èª¤ç‡: {current_value:.2%}\né–¾å€¼: {threshold:.2%}"
        self.send_alert(message)
    
    def send_content_alert(self, rule_name, current_value, threshold):
        """ç™¼é€å…§å®¹ç™¼å¸ƒå‘Šè­¦"""
        message = f"å‘Šè­¦: {rule_name}\nç•¶å‰ç™¼å¸ƒç‡: {current_value}/å°æ™‚\né–¾å€¼: {threshold}/å°æ™‚"
        self.send_alert(message)
    
    def send_alert(self, message):
        """ç™¼é€å‘Šè­¦é€šçŸ¥"""
        # ç™¼é€éƒµä»¶
        if self.alert_config.get('email_enabled'):
            self.send_email_alert(message)
        
        # ç™¼é€Slacké€šçŸ¥
        if self.alert_config.get('slack_enabled'):
            self.send_slack_alert(message)
        
        # WebSocketå¯¦æ™‚é€šçŸ¥
        asyncio.create_task(self.broadcast_alert(message))
    
    def send_email_alert(self, message):
        """ç™¼é€éƒµä»¶å‘Šè­¦"""
        try:
            smtp_config = self.alert_config['email']
            
            msg = MIMEMultipart()
            msg['From'] = smtp_config['from']
            msg['To'] = ', '.join(smtp_config['to'])
            msg['Subject'] = "MKing Friend ç³»çµ±å‘Šè­¦"
            
            msg.attach(MIMEText(message, 'plain', 'utf-8'))
            
            server = smtplib.SMTP(smtp_config['host'], smtp_config['port'])
            server.starttls()
            server.login(smtp_config['username'], smtp_config['password'])
            server.send_message(msg)
            server.quit()
            
            self.logger.info("éƒµä»¶å‘Šè­¦ç™¼é€æˆåŠŸ")
            
        except Exception as e:
            self.logger.error(f"éƒµä»¶å‘Šè­¦ç™¼é€å¤±æ•—: {e}")
    
    def send_slack_alert(self, message):
        """ç™¼é€Slackå‘Šè­¦"""
        try:
            slack_config = self.alert_config['slack']
            
            payload = {
                'text': f"ğŸš¨ MKing Friend å‘Šè­¦\n{message}",
                'channel': slack_config['channel'],
                'username': 'MonitorBot'
            }
            
            response = requests.post(
                slack_config['webhook_url'],
                json=payload,
                timeout=10
            )
            
            if response.status_code == 200:
                self.logger.info("Slackå‘Šè­¦ç™¼é€æˆåŠŸ")
            else:
                self.logger.error(f"Slackå‘Šè­¦ç™¼é€å¤±æ•—: {response.status_code}")
                
        except Exception as e:
            self.logger.error(f"Slackå‘Šè­¦ç™¼é€å¤±æ•—: {e}")
    
    async def broadcast_alert(self, message):
        """å»£æ’­å‘Šè­¦åˆ°WebSocketå®¢æˆ¶ç«¯"""
        if self.websocket_clients:
            alert_data = {
                'type': 'alert',
                'message': message,
                'timestamp': datetime.now().isoformat()
            }
            
            # å‘æ‰€æœ‰é€£æ¥çš„å®¢æˆ¶ç«¯ç™¼é€å‘Šè­¦
            disconnected_clients = set()
            for client in self.websocket_clients:
                try:
                    await client.send(json.dumps(alert_data))
                except websockets.exceptions.ConnectionClosed:
                    disconnected_clients.add(client)
            
            # ç§»é™¤æ–·é–‹çš„é€£æ¥
            self.websocket_clients -= disconnected_clients
    
    async def websocket_handler(self, websocket, path):
        """WebSocketé€£æ¥è™•ç†"""
        self.websocket_clients.add(websocket)
        self.logger.info(f"æ–°çš„WebSocketé€£æ¥: {websocket.remote_address}")
        
        try:
            async for message in websocket:
                # è™•ç†å®¢æˆ¶ç«¯æ¶ˆæ¯
                data = json.loads(message)
                
                if data.get('type') == 'get_metrics':
                    # ç™¼é€å¯¦æ™‚æŒ‡æ¨™
                    metrics = self.get_real_time_metrics()
                    await websocket.send(json.dumps({
                        'type': 'metrics',
                        'data': metrics,
                        'timestamp': datetime.now().isoformat()
                    }))
                    
        except websockets.exceptions.ConnectionClosed:
            pass
        finally:
            self.websocket_clients.discard(websocket)
            self.logger.info(f"WebSocketé€£æ¥æ–·é–‹: {websocket.remote_address}")
    
    def get_real_time_metrics(self):
        """ç²å–å¯¦æ™‚æŒ‡æ¨™"""
        return {
            'active_users': self.get_current_active_users(),
            'error_rate': self.get_error_rate(),
            'content_publish_rate': self.get_content_publish_rate(),
            'timestamp': datetime.now().isoformat()
        }
    
    async def start_monitoring(self):
        """é–‹å§‹ç›£æ§"""
        self.monitoring_active = True
        self.setup_default_rules()
        
        self.logger.info("å¯¦æ™‚ç›£æ§å·²å•Ÿå‹•")
        
        while self.monitoring_active:
            try:
                # æª¢æŸ¥å‘Šè­¦è¦å‰‡
                self.check_alert_rules()
                
                # å»£æ’­å¯¦æ™‚æŒ‡æ¨™
                if self.websocket_clients:
                    metrics = self.get_real_time_metrics()
                    await self.broadcast_metrics(metrics)
                
                # ç­‰å¾…30ç§’
                await asyncio.sleep(30)
                
            except Exception as e:
                self.logger.error(f"ç›£æ§å¾ªç’°éŒ¯èª¤: {e}")
                await asyncio.sleep(5)
    
    async def broadcast_metrics(self, metrics):
        """å»£æ’­å¯¦æ™‚æŒ‡æ¨™"""
        metrics_data = {
            'type': 'metrics_update',
            'data': metrics
        }
        
        disconnected_clients = set()
        for client in self.websocket_clients:
            try:
                await client.send(json.dumps(metrics_data))
            except websockets.exceptions.ConnectionClosed:
                disconnected_clients.add(client)
        
        self.websocket_clients -= disconnected_clients
    
    def stop_monitoring(self):
        """åœæ­¢ç›£æ§"""
        self.monitoring_active = False
        self.logger.info("å¯¦æ™‚ç›£æ§å·²åœæ­¢")
```

### 2.3 å ±è¡¨ç”Ÿæˆç³»çµ±

```python
# è‡ªå‹•åŒ–å ±è¡¨ç”Ÿæˆç³»çµ±
from jinja2 import Template
import pdfkit
from datetime import datetime, timedelta
import matplotlib.pyplot as plt
import seaborn as sns
import base64
from io import BytesIO

class ReportGenerator:
    def __init__(self, analytics_engine):
        self.analytics_engine = analytics_engine
        self.setup_logging()
        
        # è¨­ç½®ä¸­æ–‡å­—é«”
        plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS']
        plt.rcParams['axes.unicode_minus'] = False
    
    def setup_logging(self):
        """è¨­ç½®æ—¥èªŒè¨˜éŒ„"""
        self.logger = logging.getLogger(__name__)
    
    def generate_chart(self, data, chart_type, title, figsize=(10, 6)):
        """ç”Ÿæˆåœ–è¡¨"""
        plt.figure(figsize=figsize)
        
        if chart_type == 'line':
            df = pd.DataFrame(data)
            plt.plot(df.iloc[:, 0], df.iloc[:, 1])
            plt.xticks(rotation=45)
        
        elif chart_type == 'bar':
            df = pd.DataFrame(data)
            plt.bar(df.iloc[:, 0], df.iloc[:, 1])
            plt.xticks(rotation=45)
        
        elif chart_type == 'pie':
            df = pd.DataFrame(data)
            plt.pie(df.iloc[:, 1], labels=df.iloc[:, 0], autopct='%1.1f%%')
        
        elif chart_type == 'heatmap':
            df = pd.DataFrame(data)
            sns.heatmap(df, annot=True, cmap='YlOrRd')
        
        plt.title(title)
        plt.tight_layout()
        
        # è½‰æ›ç‚ºbase64å­—ç¬¦ä¸²
        buffer = BytesIO()
        plt.savefig(buffer, format='png', dpi=300, bbox_inches='tight')
        buffer.seek(0)
        chart_base64 = base64.b64encode(buffer.getvalue()).decode()
        plt.close()
        
        return chart_base64
    
    def generate_daily_report(self, date=None):
        """ç”Ÿæˆæ—¥å ±"""
        if not date:
            date = datetime.now().date()
        
        start_date = datetime.combine(date, datetime.min.time())
        end_date = start_date + timedelta(days=1)
        
        # ç²å–æ•¸æ“š
        user_data = self.analytics_engine.get_user_analytics(start_date, end_date)
        content_data = self.analytics_engine.get_content_analytics(start_date, end_date)
        social_data = self.analytics_engine.get_social_analytics(start_date, end_date)
        
        # ç”Ÿæˆåœ–è¡¨
        charts = {}
        
        # ç”¨æˆ¶æ´»èºåº¦åœ–è¡¨
        if user_data['activity_trend']:
            charts['user_activity'] = self.generate_chart(
                [(item['date'], item['daily_active_users']) for item in user_data['activity_trend']],
                'line',
                'æ—¥æ´»èºç”¨æˆ¶è¶¨å‹¢'
            )
        
        # å…§å®¹ç™¼å¸ƒåœ–è¡¨
        if content_data['content_trend']:
            charts['content_trend'] = self.generate_chart(
                [(item['date'], item['posts_count']) for item in content_data['content_trend']],
                'bar',
                'å…§å®¹ç™¼å¸ƒè¶¨å‹¢'
            )
        
        # äº’å‹•åˆ†ä½ˆåœ–è¡¨
        if social_data['interaction_trend']:
            interaction_summary = {}
            for item in social_data['interaction_trend']:
                interaction_type = item['interaction_type']
                if interaction_type not in interaction_summary:
                    interaction_summary[interaction_type] = 0
                interaction_summary[interaction_type] += item['count']
            
            charts['interaction_distribution'] = self.generate_chart(
                list(interaction_summary.items()),
                'pie',
                'äº’å‹•é¡å‹åˆ†ä½ˆ'
            )
        
        # æº–å‚™å ±è¡¨æ•¸æ“š
        report_data = {
            'date': date.strftime('%Y-%m-%d'),
            'generated_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'user_data': user_data,
            'content_data': content_data,
            'social_data': social_data,
            'charts': charts,
            'summary': self.generate_daily_summary(user_data, content_data, social_data)
        }
        
        return report_data
    
    def generate_weekly_report(self, week_start=None):
        """ç”Ÿæˆé€±å ±"""
        if not week_start:
            today = datetime.now().date()
            week_start = today - timedelta(days=today.weekday())
        
        start_date = datetime.combine(week_start, datetime.min.time())
        end_date = start_date + timedelta(days=7)
        
        # ç²å–æ•¸æ“š
        user_data = self.analytics_engine.get_user_analytics(start_date, end_date)
        content_data = self.analytics_engine.get_content_analytics(start_date, end_date)
        social_data = self.analytics_engine.get_social_analytics(start_date, end_date)
        business_data = self.analytics_engine.get_business_metrics(start_date, end_date)
        
        # ç”Ÿæˆåœ–è¡¨
        charts = {}
        
        # ç”¨æˆ¶è¨»å†Šè¶¨å‹¢
        if user_data['registration_trend']:
            charts['registration_trend'] = self.generate_chart(
                [(item['date'], item['new_users']) for item in user_data['registration_trend']],
                'line',
                'ç”¨æˆ¶è¨»å†Šè¶¨å‹¢'
            )
        
        # å…§å®¹é¡å‹åˆ†ä½ˆ
        if content_data['content_type_distribution']:
            charts['content_type_dist'] = self.generate_chart(
                [(item['content_type'], item['count']) for item in content_data['content_type_distribution']],
                'bar',
                'å…§å®¹é¡å‹åˆ†ä½ˆ'
            )
        
        # ç”¨æˆ¶ç•™å­˜ç‡
        if user_data['retention_analysis']:
            retention_data = user_data['retention_analysis']
            charts['retention_analysis'] = self.generate_chart(
                [(item['cohort_date'], item['day_7_retention_rate']) for item in retention_data],
                'line',
                '7æ—¥ç•™å­˜ç‡è¶¨å‹¢'
            )
        
        # æº–å‚™å ±è¡¨æ•¸æ“š
        report_data = {
            'week_start': week_start.strftime('%Y-%m-%d'),
            'week_end': (week_start + timedelta(days=6)).strftime('%Y-%m-%d'),
            'generated_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'user_data': user_data,
            'content_data': content_data,
            'social_data': social_data,
            'business_data': business_data,
            'charts': charts,
            'summary': self.generate_weekly_summary(user_data, content_data, social_data, business_data)
        }
        
        return report_data
    
    def generate_monthly_report(self, month_start=None):
        """ç”Ÿæˆæœˆå ±"""
        if not month_start:
            today = datetime.now().date()
            month_start = today.replace(day=1)
        
        start_date = datetime.combine(month_start, datetime.min.time())
        # è¨ˆç®—æœˆæœ«
        if month_start.month == 12:
            next_month = month_start.replace(year=month_start.year + 1, month=1)
        else:
            next_month = month_start.replace(month=month_start.month + 1)
        end_date = datetime.combine(next_month, datetime.min.time())
        
        # ç²å–æ•¸æ“š
        user_data = self.analytics_engine.get_user_analytics(start_date, end_date)
        content_data = self.analytics_engine.get_content_analytics(start_date, end_date)
        social_data = self.analytics_engine.get_social_analytics(start_date, end_date)
        business_data = self.analytics_engine.get_business_metrics(start_date, end_date)
        
        # ç”Ÿæˆæ›´è©³ç´°çš„åœ–è¡¨
        charts = {}
        
        # å¤šç¶­åº¦ç”¨æˆ¶åˆ†æ
        if user_data['registration_trend'] and user_data['activity_trend']:
            # å‰µå»ºé›™è»¸åœ–è¡¨
            fig, ax1 = plt.subplots(figsize=(12, 6))
            
            reg_data = user_data['registration_trend']
            act_data = user_data['activity_trend']
            
            dates = [item['date'] for item in reg_data]
            new_users = [item['new_users'] for item in reg_data]
            
            ax1.plot(dates, new_users, 'b-', label='æ–°ç”¨æˆ¶è¨»å†Š')
            ax1.set_xlabel('æ—¥æœŸ')
            ax1.set_ylabel('æ–°ç”¨æˆ¶æ•¸', color='b')
            ax1.tick_params(axis='y', labelcolor='b')
            
            ax2 = ax1.twinx()
            if act_data:
                active_users = [item['daily_active_users'] for item in act_data]
                ax2.plot(dates[:len(active_users)], active_users, 'r-', label='æ—¥æ´»èºç”¨æˆ¶')
                ax2.set_ylabel('æ´»èºç”¨æˆ¶æ•¸', color='r')
                ax2.tick_params(axis='y', labelcolor='r')
            
            plt.title('ç”¨æˆ¶å¢é•·èˆ‡æ´»èºåº¦åˆ†æ')
            plt.xticks(rotation=45)
            plt.tight_layout()
            
            buffer = BytesIO()
            plt.savefig(buffer, format='png', dpi=300, bbox_inches='tight')
            buffer.seek(0)
            charts['user_comprehensive'] = base64.b64encode(buffer.getvalue()).decode()
            plt.close()
        
        # å…§å®¹è¡¨ç¾ç†±åŠ›åœ–
        if content_data['engagement_analysis']:
            engagement_df = pd.DataFrame(content_data['engagement_analysis'])
            if len(engagement_df) > 0:
                # å‰µå»ºç›¸é—œæ€§çŸ©é™£
                corr_columns = ['total_likes', 'total_comments', 'total_shares', 'total_posts']
                available_columns = [col for col in corr_columns if col in engagement_df.columns]
                
                if len(available_columns) > 1:
                    corr_matrix = engagement_df[available_columns].corr()
                    
                    plt.figure(figsize=(8, 6))
                    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0)
                    plt.title('å…§å®¹äº’å‹•æŒ‡æ¨™ç›¸é—œæ€§åˆ†æ')
                    plt.tight_layout()
                    
                    buffer = BytesIO()
                    plt.savefig(buffer, format='png', dpi=300, bbox_inches='tight')
                    buffer.seek(0)
                    charts['engagement_correlation'] = base64.b64encode(buffer.getvalue()).decode()
                    plt.close()
        
        # æº–å‚™å ±è¡¨æ•¸æ“š
        report_data = {
            'month': month_start.strftime('%Y-%m'),
            'generated_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'user_data': user_data,
            'content_data': content_data,
            'social_data': social_data,
            'business_data': business_data,
            'charts': charts,
            'summary': self.generate_monthly_summary(user_data, content_data, social_data, business_data),
            'recommendations': self.generate_recommendations(user_data, content_data, social_data, business_data)
        }
        
        return report_data
    
    def generate_daily_summary(self, user_data, content_data, social_data):
        """ç”Ÿæˆæ—¥å ±æ‘˜è¦"""
        summary = {
            'total_active_users': 0,
            'total_new_posts': 0,
            'total_interactions': 0,
            'key_insights': []
        }
        
        # è¨ˆç®—ç¸½æ•¸
        if user_data['activity_trend']:
            summary['total_active_users'] = sum(item['daily_active_users'] for item in user_data['activity_trend'])
        
        if content_data['content_trend']:
            summary['total_new_posts'] = sum(item['posts_count'] for item in content_data['content_trend'])
        
        if social_data['interaction_trend']:
            summary['total_interactions'] = sum(item['count'] for item in social_data['interaction_trend'])
        
        # ç”Ÿæˆæ´å¯Ÿ
        if summary['total_active_users'] > 100:
            summary['key_insights'].append("ç”¨æˆ¶æ´»èºåº¦è¡¨ç¾è‰¯å¥½")
        elif summary['total_active_users'] < 50:
            summary['key_insights'].append("ç”¨æˆ¶æ´»èºåº¦åä½ï¼Œéœ€è¦é—œæ³¨")
        
        if summary['total_new_posts'] > 50:
            summary['key_insights'].append("å…§å®¹å‰µä½œæ´»èº")
        elif summary['total_new_posts'] < 10:
            summary['key_insights'].append("å…§å®¹å‰µä½œä¸è¶³ï¼Œéœ€è¦æ¿€å‹µæªæ–½")
        
        return summary
    
    def generate_weekly_summary(self, user_data, content_data, social_data, business_data):
        """ç”Ÿæˆé€±å ±æ‘˜è¦"""
        summary = {
            'new_users': 0,
            'avg_daily_active': 0,
            'total_content': 0,
            'engagement_rate': 0,
            'growth_insights': []
        }
        
        # è¨ˆç®—æŒ‡æ¨™
        if user_data['registration_trend']:
            summary['new_users'] = sum(item['new_users'] for item in user_data['registration_trend'])
        
        if user_data['activity_trend']:
            daily_active = [item['daily_active_users'] for item in user_data['activity_trend']]
            summary['avg_daily_active'] = sum(daily_active) / len(daily_active) if daily_active else 0
        
        if content_data['content_trend']:
            summary['total_content'] = sum(item['posts_count'] for item in content_data['content_trend'])
        
        # è¨ˆç®—åƒèˆ‡ç‡
        if content_data['engagement_analysis']:
            engagement = content_data['engagement_analysis']
            total_engagement = sum(item.get('total_likes', 0) + item.get('total_comments', 0) + item.get('total_shares', 0) for item in engagement)
            total_posts = sum(item.get('total_posts', 0) for item in engagement)
            summary['engagement_rate'] = total_engagement / total_posts if total_posts > 0 else 0
        
        return summary
    
    def generate_monthly_summary(self, user_data, content_data, social_data, business_data):
        """ç”Ÿæˆæœˆå ±æ‘˜è¦"""
        summary = {
            'monthly_growth': 0,
            'content_performance': {},
            'user_engagement': {},
            'key_achievements': [],
            'areas_for_improvement': []
        }
        
        # è¨ˆç®—æœˆåº¦å¢é•·
        if business_data['growth_metrics']:
            growth_data = business_data['growth_metrics']
            if growth_data:
                latest_growth = growth_data[-1]
                summary['monthly_growth'] = latest_growth.get('growth_rate', 0)
        
        # å…§å®¹è¡¨ç¾åˆ†æ
        if content_data['content_type_distribution']:
            content_types = content_data['content_type_distribution']
            best_performing = max(content_types, key=lambda x: x.get('avg_likes', 0))
            summary['content_performance'] = {
                'best_type': best_performing.get('content_type', 'unknown'),
                'avg_engagement': best_performing.get('avg_likes', 0)
            }
        
        # ç”¨æˆ¶åƒèˆ‡åº¦
        if user_data['retention_analysis']:
            retention_data = user_data['retention_analysis']
            if retention_data:
                avg_retention = sum(item.get('day_7_retention_rate', 0) for item in retention_data) / len(retention_data)
                summary['user_engagement']['avg_7day_retention'] = round(avg_retention, 2)
        
        return summary
    
    def generate_recommendations(self, user_data, content_data, social_data, business_data):
        """ç”Ÿæˆæ”¹é€²å»ºè­°"""
        recommendations = []
        
        # ç”¨æˆ¶å¢é•·å»ºè­°
        if user_data['registration_trend']:
            recent_registrations = user_data['registration_trend'][-7:] if len(user_data['registration_trend']) >= 7 else user_data['registration_trend']
            avg_daily_reg = sum(item['new_users'] for item in recent_registrations) / len(recent_registrations) if recent_registrations else 0
            
            if avg_daily_reg < 5:
                recommendations.append({
                    'category': 'ç”¨æˆ¶å¢é•·',
                    'priority': 'high',
                    'suggestion': 'æ—¥å‡æ–°ç”¨æˆ¶è¨»å†Šåä½ï¼Œå»ºè­°åŠ å¼·æ¨å»£æ´»å‹•å’Œç”¨æˆ¶æ¨è–¦æ©Ÿåˆ¶',
                    'expected_impact': 'æå‡20-30%æ–°ç”¨æˆ¶è¨»å†Šç‡'
                })
        
        # å…§å®¹ç­–ç•¥å»ºè­°
        if content_data['content_type_distribution']:
            content_types = content_data['content_type_distribution']
            if content_types:
                best_type = max(content_types, key=lambda x: x.get('avg_likes', 0))
                recommendations.append({
                    'category': 'å…§å®¹ç­–ç•¥',
                    'priority': 'medium',
                    'suggestion': f"é¼“å‹µæ›´å¤š{best_type['content_type']}é¡å‹å…§å®¹å‰µä½œï¼Œè©²é¡å‹å¹³å‡ç²å¾—{best_type.get('avg_likes', 0):.1f}å€‹è®š",
                    'expected_impact': 'æå‡æ•´é«”å…§å®¹åƒèˆ‡åº¦15-25%'
                })
        
        # ç”¨æˆ¶ç•™å­˜å»ºè­°
        if user_data['retention_analysis']:
            retention_data = user_data['retention_analysis']
            if retention_data:
                avg_7day_retention = sum(item.get('day_7_retention_rate', 0) for item in retention_data) / len(retention_data)
                if avg_7day_retention < 30:
                    recommendations.append({
                        'category': 'ç”¨æˆ¶ç•™å­˜',
                        'priority': 'high',
                        'suggestion': '7æ—¥ç•™å­˜ç‡åä½ï¼Œå»ºè­°å„ªåŒ–æ–°ç”¨æˆ¶å¼•å°æµç¨‹å’Œæ—©æœŸäº’å‹•é«”é©—',
                        'expected_impact': 'æå‡7æ—¥ç•™å­˜ç‡è‡³35-40%'
                    })
        
        return recommendations
    
    def generate_html_report(self, report_data, template_type='daily'):
        """ç”ŸæˆHTMLå ±è¡¨"""
        # HTMLæ¨¡æ¿
        if template_type == 'daily':
            template_str = """
            <!DOCTYPE html>
            <html>
            <head>
                <meta charset="UTF-8">
                <title>MKing Friend æ—¥å ± - {{ date }}</title>
                <style>
                    body { font-family: Arial, sans-serif; margin: 20px; }
                    .header { background: #f4f4f4; padding: 20px; border-radius: 5px; }
                    .metric { display: inline-block; margin: 10px; padding: 15px; background: #e9e9e9; border-radius: 5px; }
                    .chart { text-align: center; margin: 20px 0; }
                    .insight { background: #fff3cd; padding: 10px; margin: 10px 0; border-radius: 5px; }
                </style>
            </head>
            <body>
                <div class="header">
                    <h1>MKing Friend å¹³å°æ—¥å ±</h1>
                    <p>å ±è¡¨æ—¥æœŸ: {{ date }}</p>
                    <p>ç”Ÿæˆæ™‚é–“: {{ generated_at }}</p>
                </div>
                
                <div class="metrics">
                    <div class="metric">
                        <h3>æ´»èºç”¨æˆ¶</h3>
                        <p>{{ summary.total_active_users }}</p>
                    </div>
                    <div class="metric">
                        <h3>æ–°ç™¼å¸ƒå…§å®¹</h3>
                        <p>{{ summary.total_new_posts }}</p>
                    </div>
                    <div class="metric">
                        <h3>ç¸½äº’å‹•æ•¸</h3>
                        <p>{{ summary.total_interactions }}</p>
                    </div>
                </div>
                
                {% for chart_name, chart_data in charts.items() %}
                <div class="chart">
                    <h3>{{ chart_name }}</h3>
                    <img src="data:image/png;base64,{{ chart_data }}" alt="{{ chart_name }}">
                </div>
                {% endfor %}
                
                <div class="insights">
                    <h3>é—œéµæ´å¯Ÿ</h3>
                    {% for insight in summary.key_insights %}
                    <div class="insight">{{ insight }}</div>
                    {% endfor %}
                </div>
            </body>
            </html>
            """
        
        elif template_type == 'weekly':
            template_str = """
            <!DOCTYPE html>
            <html>
            <head>
                <meta charset="UTF-8">
                <title>MKing Friend é€±å ± - {{ week_start }} è‡³ {{ week_end }}</title>
                <style>
                    body { font-family: Arial, sans-serif; margin: 20px; }
                    .header { background: #f4f4f4; padding: 20px; border-radius: 5px; }
                    .section { margin: 30px 0; }
                    .metric-grid { display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 15px; }
                    .metric { padding: 15px; background: #e9e9e9; border-radius: 5px; text-align: center; }
                    .chart { text-align: center; margin: 20px 0; }
                    .summary { background: #d4edda; padding: 15px; border-radius: 5px; }
                </style>
            </head>
            <body>
                <div class="header">
                    <h1>MKing Friend å¹³å°é€±å ±</h1>
                    <p>å ±è¡¨é€±æœŸ: {{ week_start }} è‡³ {{ week_end }}</p>
                    <p>ç”Ÿæˆæ™‚é–“: {{ generated_at }}</p>
                </div>
                
                <div class="section">
                    <h2>æ ¸å¿ƒæŒ‡æ¨™</h2>
                    <div class="metric-grid">
                        <div class="metric">
                            <h3>æ–°ç”¨æˆ¶</h3>
                            <p>{{ summary.new_users }}</p>
                        </div>
                        <div class="metric">
                            <h3>å¹³å‡æ—¥æ´»</h3>
                            <p>{{ "%.1f"|format(summary.avg_daily_active) }}</p>
                        </div>
                        <div class="metric">
                            <h3>å…§å®¹ç¸½æ•¸</h3>
                            <p>{{ summary.total_content }}</p>
                        </div>
                        <div class="metric">
                            <h3>åƒèˆ‡ç‡</h3>
                            <p>{{ "%.2f"|format(summary.engagement_rate) }}</p>
                        </div>
                    </div>
                </div>
                
                {% for chart_name, chart_data in charts.items() %}
                <div class="section">
                    <div class="chart">
                        <h3>{{ chart_name }}</h3>
                        <img src="data:image/png;base64,{{ chart_data }}" alt="{{ chart_name }}">
                    </div>
                </div>
                {% endfor %}
                
                <div class="section">
                    <div class="summary">
                        <h3>é€±åº¦ç¸½çµ</h3>
                        <p>æœ¬é€±æ–°å¢ç”¨æˆ¶ {{ summary.new_users }} äººï¼Œå¹³å‡æ—¥æ´»èºç”¨æˆ¶ {{ "%.1f"|format(summary.avg_daily_active) }} äººã€‚</p>
                        <p>å…§å®¹å‰µä½œæ´»èºï¼Œå…±ç™¼å¸ƒ {{ summary.total_content }} ç¯‡å…§å®¹ï¼Œå¹³å‡åƒèˆ‡ç‡ç‚º {{ "%.2f"|format(summary.engagement_rate) }}ã€‚</p>
                    </div>
                </div>
            </body>
            </html>
            """
        
        else:  # monthly
            template_str = """
            <!DOCTYPE html>
            <html>
            <head>
                <meta charset="UTF-8">
                <title>MKing Friend æœˆå ± - {{ month }}</title>
                <style>
                    body { font-family: Arial, sans-serif; margin: 20px; line-height: 1.6; }
                    .header { background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 30px; border-radius: 10px; }
                    .section { margin: 40px 0; }
                    .metric-grid { display: grid; grid-template-columns: repeat(auto-fit, minmax(250px, 1fr)); gap: 20px; }
                    .metric { padding: 20px; background: #f8f9fa; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); }
                    .chart { text-align: center; margin: 30px 0; }
                    .recommendation { background: #fff3cd; padding: 15px; margin: 10px 0; border-left: 4px solid #ffc107; border-radius: 5px; }
                    .high-priority { border-left-color: #dc3545; }
                    .medium-priority { border-left-color: #fd7e14; }
                    .low-priority { border-left-color: #28a745; }
                </style>
            </head>
            <body>
                <div class="header">
                    <h1>MKing Friend å¹³å°æœˆå ±</h1>
                    <p>å ±è¡¨æœˆä»½: {{ month }}</p>
                    <p>ç”Ÿæˆæ™‚é–“: {{ generated_at }}</p>
                </div>
                
                <div class="section">
                    <h2>æœˆåº¦æ¦‚è¦½</h2>
                    <div class="metric-grid">
                        <div class="metric">
                            <h3>æœˆåº¦å¢é•·ç‡</h3>
                            <p>{{ "%.2f%"|format(summary.monthly_growth) }}</p>
                        </div>
                        <div class="metric">
                            <h3>æœ€ä½³å…§å®¹é¡å‹</h3>
                            <p>{{ summary.content_performance.best_type }}</p>
                            <small>å¹³å‡ {{ "%.1f"|format(summary.content_performance.avg_engagement) }} å€‹è®š</small>
                        </div>
                        <div class="metric">
                            <h3>7æ—¥ç•™å­˜ç‡</h3>
                            <p>{{ "%.1f%"|format(summary.user_engagement.avg_7day_retention) }}</p>
                        </div>
                    </div>
                </div>
                
                {% for chart_name, chart_data in charts.items() %}
                <div class="section">
                    <div class="chart">
                        <h3>{{ chart_name }}</h3>
                        <img src="data:image/png;base64,{{ chart_data }}" alt="{{ chart_name }}">
                    </div>
                </div>
                {% endfor %}
                
                <div class="section">
                    <h2>æ”¹é€²å»ºè­°</h2>
                    {% for rec in recommendations %}
                    <div class="recommendation {{ rec.priority }}-priority">
                        <h4>{{ rec.category }} ({{ rec.priority|upper }} å„ªå…ˆç´š)</h4>
                        <p><strong>å»ºè­°:</strong> {{ rec.suggestion }}</p>
                        <p><strong>é æœŸæ•ˆæœ:</strong> {{ rec.expected_impact }}</p>
                    </div>
                    {% endfor %}
                </div>
            </body>
            </html>
            """
        
        # æ¸²æŸ“æ¨¡æ¿
        template = Template(template_str)
        html_content = template.render(**report_data)
        
        return html_content
    
    def generate_pdf_report(self, report_data, template_type='daily', output_path=None):
        """ç”ŸæˆPDFå ±è¡¨"""
        # ç”ŸæˆHTML
        html_content = self.generate_html_report(report_data, template_type)
        
        # è¨­ç½®PDFé¸é …
        options = {
            'page-size': 'A4',
            'margin-top': '0.75in',
            'margin-right': '0.75in',
            'margin-bottom': '0.75in',
            'margin-left': '0.75in',
            'encoding': "UTF-8",
            'no-outline': None,
            'enable-local-file-access': None
        }
        
        # ç”ŸæˆPDF
        if not output_path:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            output_path = f"report_{template_type}_{timestamp}.pdf"
        
        try:
            pdfkit.from_string(html_content, output_path, options=options)
            self.logger.info(f"PDFå ±è¡¨å·²ç”Ÿæˆ: {output_path}")
            return output_path
        except Exception as e:
            self.logger.error(f"PDFç”Ÿæˆå¤±æ•—: {e}")
            return None
```

## 3. æ•¸æ“šåº«è¨­è¨ˆ

### 3.1 åˆ†ææ•¸æ“šè¡¨

```sql
-- ç”¨æˆ¶è¡Œç‚ºåˆ†æè¡¨
CREATE TABLE user_behavior_analytics (
    id SERIAL PRIMARY KEY,
    user_id INTEGER REFERENCES users(id),
    date DATE NOT NULL,
    session_count INTEGER DEFAULT 0,
    page_views INTEGER DEFAULT 0,
    time_spent INTEGER DEFAULT 0, -- ç§’
    actions_count INTEGER DEFAULT 0,
    last_activity TIMESTAMP,
    device_type VARCHAR(50),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- å…§å®¹è¡¨ç¾åˆ†æè¡¨
CREATE TABLE content_performance_analytics (
    id SERIAL PRIMARY KEY,
    content_id INTEGER REFERENCES posts(id),
    date DATE NOT NULL,
    views_count INTEGER DEFAULT 0,
    likes_count INTEGER DEFAULT 0,
    comments_count INTEGER DEFAULT 0,
    shares_count INTEGER DEFAULT 0,
    engagement_rate DECIMAL(5,4) DEFAULT 0,
    reach_count INTEGER DEFAULT 0,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- ç¤¾äº¤äº’å‹•åˆ†æè¡¨
CREATE TABLE social_interaction_analytics (
    id SERIAL PRIMARY KEY,
    date DATE NOT NULL,
    follows_count INTEGER DEFAULT 0,
    unfollows_count INTEGER DEFAULT 0,
    mentions_count INTEGER DEFAULT 0,
    direct_messages_count INTEGER DEFAULT 0,
    group_interactions_count INTEGER DEFAULT 0,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- æ¥­å‹™æŒ‡æ¨™è¡¨
CREATE TABLE business_metrics (
    id SERIAL PRIMARY KEY,
    date DATE NOT NULL,
    metric_name VARCHAR(100) NOT NULL,
    metric_value DECIMAL(15,4) NOT NULL,
    metric_type VARCHAR(50), -- daily, weekly, monthly
    category VARCHAR(50), -- user, content, revenue, engagement
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- å ±è¡¨ç”Ÿæˆè¨˜éŒ„è¡¨
CREATE TABLE report_generation_logs (
    id SERIAL PRIMARY KEY,
    report_type VARCHAR(50) NOT NULL, -- daily, weekly, monthly
    report_date DATE NOT NULL,
    generated_by INTEGER REFERENCES users(id),
    file_path VARCHAR(500),
    file_format VARCHAR(20), -- html, pdf, json, csv
    generation_time INTEGER, -- ç”Ÿæˆè€—æ™‚(ç§’)
    status VARCHAR(20) DEFAULT 'pending', -- pending, completed, failed
    error_message TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- è‡ªå®šç¾©å„€è¡¨æ¿é…ç½®è¡¨
CREATE TABLE dashboard_configs (
    id SERIAL PRIMARY KEY,
    user_id INTEGER REFERENCES users(id),
    dashboard_name VARCHAR(100) NOT NULL,
    config_json JSONB NOT NULL,
    is_default BOOLEAN DEFAULT FALSE,
    is_public BOOLEAN DEFAULT FALSE,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- æ•¸æ“šå°å‡ºè¨˜éŒ„è¡¨
CREATE TABLE data_export_logs (
    id SERIAL PRIMARY KEY,
    user_id INTEGER REFERENCES users(id),
    export_type VARCHAR(50) NOT NULL,
    date_range_start DATE,
    date_range_end DATE,
    filters_json JSONB,
    file_path VARCHAR(500),
    file_size INTEGER,
    export_time INTEGER, -- å°å‡ºè€—æ™‚(ç§’)
    status VARCHAR(20) DEFAULT 'pending',
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- å‘Šè­¦è¦å‰‡é…ç½®è¡¨
CREATE TABLE alert_rules (
    id SERIAL PRIMARY KEY,
    rule_name VARCHAR(100) NOT NULL,
    metric_name VARCHAR(100) NOT NULL,
    condition_type VARCHAR(20) NOT NULL, -- gt, lt, eq, gte, lte
    threshold_value DECIMAL(15,4) NOT NULL,
    alert_channels JSONB, -- email, slack, webhook
    is_active BOOLEAN DEFAULT TRUE,
    cooldown_minutes INTEGER DEFAULT 60,
    created_by INTEGER REFERENCES users(id),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- å‘Šè­¦è§¸ç™¼è¨˜éŒ„è¡¨
CREATE TABLE alert_triggers (
    id SERIAL PRIMARY KEY,
    rule_id INTEGER REFERENCES alert_rules(id),
    triggered_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    metric_value DECIMAL(15,4) NOT NULL,
    threshold_value DECIMAL(15,4) NOT NULL,
    alert_sent BOOLEAN DEFAULT FALSE,
    alert_channels_used JSONB,
    resolved_at TIMESTAMP,
    notes TEXT
);
```

### 3.2 ç´¢å¼•å„ªåŒ–

```sql
-- ç”¨æˆ¶è¡Œç‚ºåˆ†æç´¢å¼•
CREATE INDEX idx_user_behavior_analytics_user_date ON user_behavior_analytics(user_id, date);
CREATE INDEX idx_user_behavior_analytics_date ON user_behavior_analytics(date);
CREATE INDEX idx_user_behavior_analytics_device ON user_behavior_analytics(device_type, date);

-- å…§å®¹è¡¨ç¾åˆ†æç´¢å¼•
CREATE INDEX idx_content_performance_content_date ON content_performance_analytics(content_id, date);
CREATE INDEX idx_content_performance_date ON content_performance_analytics(date);
CREATE INDEX idx_content_performance_engagement ON content_performance_analytics(engagement_rate DESC, date);

-- ç¤¾äº¤äº’å‹•åˆ†æç´¢å¼•
CREATE INDEX idx_social_interaction_date ON social_interaction_analytics(date);

-- æ¥­å‹™æŒ‡æ¨™ç´¢å¼•
CREATE INDEX idx_business_metrics_name_date ON business_metrics(metric_name, date);
CREATE INDEX idx_business_metrics_type_category ON business_metrics(metric_type, category, date);
CREATE INDEX idx_business_metrics_date ON business_metrics(date);

-- å ±è¡¨ç”Ÿæˆè¨˜éŒ„ç´¢å¼•
CREATE INDEX idx_report_logs_type_date ON report_generation_logs(report_type, report_date);
CREATE INDEX idx_report_logs_user ON report_generation_logs(generated_by, created_at);
CREATE INDEX idx_report_logs_status ON report_generation_logs(status, created_at);

-- å„€è¡¨æ¿é…ç½®ç´¢å¼•
CREATE INDEX idx_dashboard_configs_user ON dashboard_configs(user_id, is_default);
CREATE INDEX idx_dashboard_configs_public ON dashboard_configs(is_public, created_at);

-- æ•¸æ“šå°å‡ºè¨˜éŒ„ç´¢å¼•
CREATE INDEX idx_data_export_user_date ON data_export_logs(user_id, created_at);
CREATE INDEX idx_data_export_status ON data_export_logs(status, created_at);

-- å‘Šè­¦è¦å‰‡ç´¢å¼•
CREATE INDEX idx_alert_rules_active ON alert_rules(is_active, metric_name);
CREATE INDEX idx_alert_rules_user ON alert_rules(created_by, is_active);

-- å‘Šè­¦è§¸ç™¼è¨˜éŒ„ç´¢å¼•
CREATE INDEX idx_alert_triggers_rule_time ON alert_triggers(rule_id, triggered_at);
CREATE INDEX idx_alert_triggers_unresolved ON alert_triggers(resolved_at) WHERE resolved_at IS NULL;
```

## 4. ç³»çµ±æ¶æ§‹è¨­è¨ˆ

### 4.1 æ•¸æ“šåˆ†æç³»çµ±æ¶æ§‹ç¸½è¦½

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        æ•¸æ“šåˆ†æèˆ‡å ±è¡¨ç³»çµ±                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  å‰ç«¯å±¤ (Frontend)                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   ç®¡ç†å¾Œå°      â”‚  â”‚   å„€è¡¨æ¿ç•Œé¢    â”‚  â”‚   å ±è¡¨æŸ¥çœ‹å™¨    â”‚ â”‚
â”‚  â”‚   Dashboard     â”‚  â”‚   Analytics UI  â”‚  â”‚   Report Viewer â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  APIå±¤ (API Gateway)                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   åˆ†æAPI       â”‚  â”‚   å ±è¡¨API       â”‚  â”‚   å°å‡ºAPI       â”‚ â”‚
â”‚  â”‚   Analytics API â”‚  â”‚   Report API    â”‚  â”‚   Export API    â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  æœå‹™å±¤ (Services)                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   æ•¸æ“šåˆ†æå¼•æ“  â”‚  â”‚   å ±è¡¨ç”Ÿæˆå™¨    â”‚  â”‚   å¯¦æ™‚ç›£æ§      â”‚ â”‚
â”‚  â”‚   Analytics     â”‚  â”‚   Report Gen    â”‚  â”‚   Real-time     â”‚ â”‚
â”‚  â”‚   Engine        â”‚  â”‚                 â”‚  â”‚   Monitor       â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   æ•¸æ“šæ”¶é›†å™¨    â”‚  â”‚   å‘Šè­¦ç³»çµ±      â”‚  â”‚   ä»»å‹™èª¿åº¦å™¨    â”‚ â”‚
â”‚  â”‚   Data Collectorâ”‚  â”‚   Alert System  â”‚  â”‚   Task Schedulerâ”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  æ•¸æ“šå±¤ (Data Layer)                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   PostgreSQL    â”‚  â”‚   Redis Cache   â”‚  â”‚   æ–‡ä»¶å­˜å„²      â”‚ â”‚
â”‚  â”‚   ä¸»æ•¸æ“šåº«      â”‚  â”‚   å¿«å–å±¤        â”‚  â”‚   File Storage  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   æ™‚åºæ•¸æ“šåº«    â”‚  â”‚   æ—¥èªŒå­˜å„²      â”‚  â”‚   å‚™ä»½å­˜å„²      â”‚ â”‚
â”‚  â”‚   TimescaleDB   â”‚  â”‚   Log Storage   â”‚  â”‚   Backup        â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4.2 æ•¸æ“šæµç¨‹åœ–

```
ç”¨æˆ¶è¡Œç‚ºæ•¸æ“š â”€â”€â”
              â”‚
å…§å®¹äº’å‹•æ•¸æ“š â”€â”€â”¼â”€â”€â–º æ•¸æ“šæ”¶é›†å™¨ â”€â”€â–º æ•¸æ“šé è™•ç† â”€â”€â–º æ•¸æ“šå­˜å„²
              â”‚                                    â”‚
ç³»çµ±æ—¥èªŒæ•¸æ“š â”€â”€â”˜                                    â”‚
                                                   â–¼
å¯¦æ™‚ç›£æ§ â—„â”€â”€â”€â”€ æ•¸æ“šåˆ†æå¼•æ“ â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ æ•¸æ“šæŸ¥è©¢
    â”‚              â”‚                               â”‚
    â–¼              â–¼                               â–¼
å‘Šè­¦é€šçŸ¥      åˆ†æçµæœå¿«å–                    å ±è¡¨ç”Ÿæˆ
    â”‚              â”‚                               â”‚
    â–¼              â–¼                               â–¼
é€šçŸ¥ç™¼é€      å„€è¡¨æ¿å±•ç¤º                      å ±è¡¨å°å‡º
```

## 5. å¯¦æ–½è¨ˆåŠƒ

### 5.1 ç¬¬ä¸€éšæ®µï¼šåŸºç¤åˆ†æåŠŸèƒ½ (4-6é€±)

**æ ¸å¿ƒåŠŸèƒ½**
- åŸºç¤æ•¸æ“šæ”¶é›†ç³»çµ±
- ç”¨æˆ¶è¡Œç‚ºåˆ†æ
- å…§å®¹è¡¨ç¾åˆ†æ
- ç°¡å–®å„€è¡¨æ¿
- åŸºç¤å ±è¡¨ç”Ÿæˆ

**æŠ€è¡“å¯¦ç¾**
- PostgreSQL æ•¸æ“šåº«è¨­è¨ˆ
- Python åˆ†æå¼•æ“é–‹ç™¼
- åŸºç¤ Web å„€è¡¨æ¿
- æ—¥å ±/é€±å ±ç”Ÿæˆ

**é æœŸæˆæœ**
- å®ŒæˆåŸºç¤æ•¸æ“šåˆ†æåŠŸèƒ½
- æä¾›æ ¸å¿ƒæ¥­å‹™æŒ‡æ¨™ç›£æ§
- æ”¯æ´åŸºç¤å ±è¡¨å°å‡º

### 5.2 ç¬¬äºŒéšæ®µï¼šé€²éšåˆ†æåŠŸèƒ½ (6-8é€±)

**æ ¸å¿ƒåŠŸèƒ½**
- å¯¦æ™‚æ•¸æ“šç›£æ§
- é æ¸¬æ€§åˆ†æ
- ç”¨æˆ¶ç•™å­˜åˆ†æ
- è‡ªå®šç¾©å„€è¡¨æ¿
- å‘Šè­¦ç³»çµ±

**æŠ€è¡“å¯¦ç¾**
- Redis å¿«å–å±¤
- WebSocket å¯¦æ™‚é€šä¿¡
- æ©Ÿå™¨å­¸ç¿’æ¨¡å‹
- å‘Šè­¦è¦å‰‡å¼•æ“
- é«˜ç´šå¯è¦–åŒ–

**é æœŸæˆæœ**
- å¯¦ç¾å¯¦æ™‚ç›£æ§èƒ½åŠ›
- æä¾›é æ¸¬æ€§æ´å¯Ÿ
- æ”¯æ´è‡ªå®šç¾©åˆ†æ

### 5.3 ç¬¬ä¸‰éšæ®µï¼šå„ªåŒ–èˆ‡æ“´å±• (4-6é€±)

**æ ¸å¿ƒåŠŸèƒ½**
- æ€§èƒ½å„ªåŒ–
- é«˜ç´šåˆ†æç®—æ³•
- å¤šç¶­åº¦åˆ†æ
- API é–‹æ”¾
- ç§»å‹•ç«¯æ”¯æ´

**æŠ€è¡“å¯¦ç¾**
- æŸ¥è©¢å„ªåŒ–
- åˆ†æ•£å¼è™•ç†
- é«˜ç´šçµ±è¨ˆåˆ†æ
- RESTful API
- éŸ¿æ‡‰å¼è¨­è¨ˆ

**é æœŸæˆæœ**
- ç³»çµ±æ€§èƒ½å¤§å¹…æå‡
- æ”¯æ´è¤‡é›œåˆ†æéœ€æ±‚
- æä¾›å®Œæ•´ API æ¥å£

## 6. æŠ€è¡“å»ºè­°

### 6.1 æ¨è–¦æŠ€è¡“æ£§

**å¾Œç«¯æŠ€è¡“**
- **æ•¸æ“šåˆ†æ**: Python + Pandas + NumPy + SciPy
- **Webæ¡†æ¶**: FastAPI / Flask
- **ä»»å‹™éšŠåˆ—**: Celery + Redis
- **æ•¸æ“šåº«**: PostgreSQL + TimescaleDB
- **å¿«å–**: Redis
- **ç›£æ§**: Prometheus + Grafana

**å‰ç«¯æŠ€è¡“**
- **æ¡†æ¶**: React / Vue.js
- **åœ–è¡¨åº«**: Chart.js / D3.js / Plotly.js
- **UIçµ„ä»¶**: Ant Design / Material-UI
- **ç‹€æ…‹ç®¡ç†**: Redux / Vuex

**æ•¸æ“šè™•ç†**
- **ETLå·¥å…·**: Apache Airflow (å¯é¸)
- **æ•¸æ“šå¯è¦–åŒ–**: Matplotlib + Seaborn
- **å ±è¡¨ç”Ÿæˆ**: Jinja2 + wkhtmltopdf
- **æ©Ÿå™¨å­¸ç¿’**: Scikit-learn

### 6.2 æˆæœ¬ä¼°ç®—

**é–‹ç™¼æˆæœ¬**
- ç¬¬ä¸€éšæ®µ: 320-480å°æ™‚ (2-3äººæœˆ)
- ç¬¬äºŒéšæ®µ: 480-640å°æ™‚ (3-4äººæœˆ)
- ç¬¬ä¸‰éšæ®µ: 320-480å°æ™‚ (2-3äººæœˆ)
- **ç¸½è¨ˆ**: 1120-1600å°æ™‚ (7-10äººæœˆ)

**é‹ç‡Ÿæˆæœ¬** (æœˆåº¦)
- æœå‹™å™¨è³‡æº: $100-300
- æ•¸æ“šå­˜å„²: $50-150
- ç¬¬ä¸‰æ–¹æœå‹™: $20-50
- **ç¸½è¨ˆ**: $170-500/æœˆ

### 6.3 é—œéµæŒ‡æ¨™

**ç³»çµ±æ€§èƒ½**
- æŸ¥è©¢éŸ¿æ‡‰æ™‚é–“: <2ç§’
- å ±è¡¨ç”Ÿæˆæ™‚é–“: <30ç§’
- ç³»çµ±å¯ç”¨æ€§: >99.5%
- æ•¸æ“šè™•ç†èƒ½åŠ›: >10è¬æ¢è¨˜éŒ„/åˆ†é˜

**åˆ†ææº–ç¢ºæ€§**
- æ•¸æ“šæº–ç¢ºç‡: >99%
- é æ¸¬æº–ç¢ºç‡: >80%
- ç•°å¸¸æª¢æ¸¬ç‡: >95%

**ç”¨æˆ¶é«”é©—**
- å„€è¡¨æ¿è¼‰å…¥æ™‚é–“: <3ç§’
- å ±è¡¨å°å‡ºæˆåŠŸç‡: >98%
- ç”¨æˆ¶æ»¿æ„åº¦: >4.0/5.0

## 7. é¢¨éšªè©•ä¼°èˆ‡æ‡‰å°

### 7.1 æŠ€è¡“é¢¨éšª

**æ•¸æ“šè™•ç†æ€§èƒ½ç“¶é ¸**
- **é¢¨éšª**: å¤§é‡æ•¸æ“šè™•ç†å°è‡´ç³»çµ±éŸ¿æ‡‰ç·©æ…¢
- **æ‡‰å°**: å¯¦æ–½æ•¸æ“šåˆ†ç‰‡ã€æŸ¥è©¢å„ªåŒ–ã€å¿«å–ç­–ç•¥
- **é é˜²**: æ€§èƒ½æ¸¬è©¦ã€å®¹é‡è¦åŠƒ

**æ•¸æ“šæº–ç¢ºæ€§å•é¡Œ**
- **é¢¨éšª**: æ•¸æ“šæ”¶é›†æˆ–è™•ç†éŒ¯èª¤å½±éŸ¿åˆ†æçµæœ
- **æ‡‰å°**: æ•¸æ“šé©—è­‰æ©Ÿåˆ¶ã€å¤šé‡æ ¡é©—ã€ç•°å¸¸æª¢æ¸¬
- **é é˜²**: å®Œå–„çš„æ¸¬è©¦è¦†è“‹ã€æ•¸æ“šå“è³ªç›£æ§

**ç³»çµ±æ“´å±•æ€§é™åˆ¶**
- **é¢¨éšª**: ç”¨æˆ¶å¢é•·å°è‡´ç³»çµ±ç„¡æ³•æ‰¿è¼‰
- **æ‡‰å°**: å¾®æœå‹™æ¶æ§‹ã€æ°´å¹³æ“´å±•ã€è² è¼‰å‡è¡¡
- **é é˜²**: å¯æ“´å±•çš„æ¶æ§‹è¨­è¨ˆã€æ€§èƒ½ç›£æ§

### 7.2 æ¥­å‹™é¢¨éšª

**æ•¸æ“šéš±ç§åˆè¦**
- **é¢¨éšª**: é•åæ•¸æ“šä¿è­·æ³•è¦
- **æ‡‰å°**: æ•¸æ“šåŒ¿ååŒ–ã€æ¬Šé™æ§åˆ¶ã€åˆè¦å¯©è¨ˆ
- **é é˜²**: éš±ç§è¨­è¨ˆåŸå‰‡ã€æ³•å¾‹è«®è©¢

**åˆ†æçµæœèª¤å°**
- **é¢¨éšª**: éŒ¯èª¤çš„åˆ†æçµè«–å½±éŸ¿æ¥­å‹™æ±ºç­–
- **æ‡‰å°**: å¤šç¶­åº¦é©—è­‰ã€å°ˆå®¶å¯©æ ¸ã€ç½®ä¿¡åº¦æ¨™ç¤º
- **é é˜²**: çµ±è¨ˆå­¸åŸ¹è¨“ã€æ–¹æ³•è«–æ¨™æº–åŒ–

## 8. æœªä¾†æ“´å±•è¦åŠƒ

### 8.1 ä¸­æœŸåŠŸèƒ½ (6-12å€‹æœˆ)

**æ™ºèƒ½åŒ–åˆ†æ**
- è‡ªå‹•ç•°å¸¸æª¢æ¸¬
- æ™ºèƒ½æ´å¯Ÿç”Ÿæˆ
- é æ¸¬æ€§ç¶­è­·
- è‡ªé©æ‡‰å‘Šè­¦é–¾å€¼

**é«˜ç´šå¯è¦–åŒ–**
- 3Dæ•¸æ“šå¯è¦–åŒ–
- äº’å‹•å¼åœ–è¡¨
- åœ°ç†ä¿¡æ¯åˆ†æ
- å¯¦æ™‚æ•¸æ“šæµå¯è¦–åŒ–

**å”ä½œåŠŸèƒ½**
- å ±è¡¨åˆ†äº«èˆ‡å”ä½œ
- è¨»é‡‹èˆ‡è¨è«–
- ç‰ˆæœ¬æ§åˆ¶
- åœ˜éšŠå„€è¡¨æ¿

### 8.2 é•·æœŸåŠŸèƒ½ (1-2å¹´)

**äººå·¥æ™ºèƒ½æ•´åˆ**
- è‡ªç„¶èªè¨€æŸ¥è©¢
- æ™ºèƒ½å ±è¡¨ç”Ÿæˆ
- è‡ªå‹•åŒ–æ´å¯Ÿç™¼ç¾
- å°è©±å¼åˆ†æç•Œé¢

**å¤§æ•¸æ“šè™•ç†**
- æµå¼æ•¸æ“šè™•ç†
- åˆ†æ•£å¼è¨ˆç®—
- å¯¦æ™‚æ©Ÿå™¨å­¸ç¿’
- å¤šæºæ•¸æ“šæ•´åˆ

**ç”Ÿæ…‹ç³»çµ±æ•´åˆ**
- ç¬¬ä¸‰æ–¹æ•¸æ“šæºæ¥å…¥
- APIç”Ÿæ…‹å»ºè¨­
- æ’ä»¶ç³»çµ±
- é–‹æ”¾å¹³å°

## 9. æ³¨æ„äº‹é …

**æŠ€è¡“é¸æ“‡**
- å„ªå…ˆé¸æ“‡é–‹æºå…è²»æŠ€è¡“ï¼Œæ§åˆ¶æˆæœ¬
- ç¢ºä¿æŠ€è¡“æ£§çš„é•·æœŸå¯ç¶­è­·æ€§
- è€ƒæ…®åœ˜éšŠæŠ€è¡“èƒ½åŠ›å’Œå­¸ç¿’æˆæœ¬

**æ•¸æ“šå®‰å…¨**
- å¯¦æ–½åš´æ ¼çš„æ•¸æ“šè¨ªå•æ§åˆ¶
- å®šæœŸé€²è¡Œå®‰å…¨å¯©è¨ˆ
- éµå¾ªæ•¸æ“šä¿è­·æœ€ä½³å¯¦è¸

**æ€§èƒ½å„ªåŒ–**
- å¾è¨­è¨ˆéšæ®µå°±è€ƒæ…®æ€§èƒ½å•é¡Œ
- å¯¦æ–½æœ‰æ•ˆçš„å¿«å–ç­–ç•¥
- å®šæœŸé€²è¡Œæ€§èƒ½èª¿å„ª

**ç”¨æˆ¶é«”é©—**
- ç°¡åŒ–è¤‡é›œçš„åˆ†æåŠŸèƒ½
- æä¾›ç›´è§€çš„å¯è¦–åŒ–ç•Œé¢
- ç¢ºä¿ç³»çµ±éŸ¿æ‡‰é€Ÿåº¦

**æŒçºŒæ”¹é€²**
- æ”¶é›†ç”¨æˆ¶åé¥‹ä¸¦æŒçºŒå„ªåŒ–
- è·Ÿè¹¤è¡Œæ¥­æœ€ä½³å¯¦è¸
- å®šæœŸè©•ä¼°å’Œå‡ç´šæŠ€è¡“æ£§

---

*æœ¬è¦åŠƒæ–‡ä»¶ç‚º MKing Friend å¹³å°æ•¸æ“šåˆ†æèˆ‡å ±è¡¨åŠŸèƒ½çš„è©³ç´°è¨­è¨ˆæ–¹æ¡ˆï¼Œä»¥é–‹æºå…è²»æŠ€è¡“ç‚ºä¸»ï¼Œæ—¨åœ¨ç‚ºå¹³å°æä¾›å¼·å¤§çš„æ•¸æ“šæ´å¯Ÿèƒ½åŠ›ï¼Œæ”¯æ´æ•¸æ“šé©…å‹•çš„æ¥­å‹™æ±ºç­–ã€‚*